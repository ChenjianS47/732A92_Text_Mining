{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is the task of sorting text documents into predefined classes. The concrete problem you will be working on in this lab is the classification of texts with respect to their political affiliation. The specific texts you are going to classify are speeches held in the [Riksdag](https://www.riksdagen.se/en/), the Swedish national legislature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before starting with this lab, here is a quick reminder about our [Rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins) and the [Policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for this lab comes from [The Riksdag’s Open Data](https://data.riksdagen.se/in-english/). We have tokenized the speeches and put them into two compressed [JSON](https://en.wikipedia.org/wiki/JSON) files:\n",
    "\n",
    "* `speeches-201718.json.bz2` (speeches from the 2017/2018 parliamentary session)\n",
    "* `speeches-201819.json.bz2` (ditto, from the 2018/2019 session)\n",
    "\n",
    "We start by loading these files into two separate data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open('speeches-201718.json.bz2') as source:\n",
    "    speeches_201718 = pd.read_json(source)\n",
    "\n",
    "with bz2.open('speeches-201819.json.bz2') as source:\n",
    "    speeches_201819 = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the two data frames, you can see that there are three labelled columns: `id` (the official speech ID), `words` (the space-separated words of the speech), and `party` (the party of the speaker, represented by its customary abbreviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H5-002-004</td>\n",
       "      <td>eders majestäter eders kungliga högheter herr ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H5-003-001</td>\n",
       "      <td>aktuell debatt om situationen för ensamkommand...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H5-003-002</td>\n",
       "      <td>herr talman och ledamöter jag vill börja med a...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H5-003-003</td>\n",
       "      <td>herr talman åhörare den här debatten handlar a...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5-003-004</td>\n",
       "      <td>herr talman ansvar och rättssäkerhet är två or...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              words party\n",
       "0  H5-002-004  eders majestäter eders kungliga högheter herr ...     S\n",
       "1  H5-003-001  aktuell debatt om situationen för ensamkommand...     V\n",
       "2  H5-003-002  herr talman och ledamöter jag vill börja med a...     S\n",
       "3  H5-003-003  herr talman åhörare den här debatten handlar a...     M\n",
       "4  H5-003-004  herr talman ansvar och rättssäkerhet är två or...    SD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201718.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the lab, we will be using the speeches from 2017/2018 as our training data, and the speeches from 2018/2019 as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = speeches_201718, speeches_201819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later reference, we store the sorted list of party abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'KD', 'L', 'M', 'MP', 'S', 'SD', 'V']\n"
     ]
    }
   ],
   "source": [
    "parties = sorted(training_data['party'].unique())\n",
    "print(parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to get to know the data better by producing a simple visualization.\n",
    "\n",
    "If you are not familiar with the Swedish political system and the parties represented in the Riksdag in particular, then we suggest that you have a look at the Wikipedia article about the [2018 Swedish general election](https://en.wikipedia.org/wiki/2018_Swedish_general_election).\n",
    "\n",
    "For the lab, we ask you to compare the two data frames with respect to the distribution of the speeches over the different parties. Write code to generate two bar plots that visualize this information, one for the 2017/2018 speeches and one for the 2018/2019 speeches. Inspect the two plots, and compare them\n",
    "\n",
    "* to each other\n",
    "* to the results of the 2014 and the 2018 general elections\n",
    "\n",
    "Summarize your observations in a short text in the cell below.\n",
    "\n",
    "**Tip:** If you need help with creating bar plots, [Bar Plot using Pandas](https://dfrieds.com/data-visualizations/bar-plot-python-pandas) provides a useful tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = training_data[\"party\"].unique()\n",
    "y_tr = training_data[\"party\"].value_counts()\n",
    "x_tst = test_data[\"party\"].unique()\n",
    "y_tst = test_data[\"party\"].value_counts()\n",
    "r_tr = np.arange(len(y_tr))\n",
    "r_tst = [x + 0.25 for x in r_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.DataFrame(\n",
    "   {  \"years\":\"2017-2018\",\n",
    "       \"party\":x_tr,\n",
    "       \"count\":y_tr   }   )\n",
    "df2= pd.DataFrame(\n",
    "   {  \"years\":\"2018-2019\",\n",
    "       \"party\":x_tst,\n",
    "       \"count\":y_tst   }   )\n",
    "df = pd.concat([df1,df2]).pivot('party',columns=['years'], values=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "labels= df.index\n",
    "x = np.arange(len(labels)) \n",
    "plt.bar(x-0.3,df[('count', '2017-2018')],0.3,label='2017-2018')\n",
    "plt.bar(x,df[('count', '2018-2019')],0.3,label='2018-2019')\n",
    "for index, value in enumerate(df[('count', '2017-2018')]):\n",
    "    plt.text(index-0.5,value,  str(value)) \n",
    "for index, value in enumerate(df[('count', '2018-2019')]):\n",
    "    plt.text(index,value,  str(value)) \n",
    "plt.ylabel('Counts')\n",
    "plt.title('')\n",
    "plt.xlabel('parties')\n",
    "plt.xticks(ticks=x, labels=labels)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Enter your summary here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "According to the plot above, some parties like C, MP, S and V, their speech counts decreased compared to the past data, and as for parties like KD, L, M and SD, their speech counts increaed compared to the past data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to train and evaluate a classifier. More specifically, we ask you to train a [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) classifier. You will have to\n",
    "\n",
    "1. vectorize the speeches in the training data\n",
    "2. instantiate and fit the Naive Bayes model\n",
    "3. evaluate the model on the test data\n",
    "\n",
    "The scikit-learn library provides a convenience class [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that allows you to solve the first two tasks with very compact code. For the evaluation you can use the function [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), which will report per-class precision, recall and F1, as well as overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to train and evaluate a Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = training_data.drop([\"id\",\"party\"], axis=1), training_data[\"party\"]\n",
    "X_test, y_test = test_data.drop([\"party\"], axis=1), test_data[\"party\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =Pipeline( [(\"CountVectorizer\", CountVectorizer()), (\"MultinomialNB\", MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.98      0.45      0.62       865\n",
      "          KD       0.98      0.33      0.49       743\n",
      "           L       1.00      0.36      0.53       719\n",
      "           M       0.62      0.95      0.75      2370\n",
      "          MP       0.89      0.64      0.74      1481\n",
      "           S       0.74      0.96      0.84      4261\n",
      "          SD       0.96      0.59      0.73      1010\n",
      "           V       0.95      0.66      0.78       894\n",
      "\n",
      "    accuracy                           0.76     12343\n",
      "   macro avg       0.89      0.62      0.69     12343\n",
      "weighted avg       0.82      0.76      0.74     12343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train['words'],y_train)\n",
    "pred_tr = pipe.predict(X_train['words'])\n",
    "print(classification_report(y_train, pred_tr, target_names=parties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.04      0.07       671\n",
      "          KD       0.70      0.02      0.03       821\n",
      "           L       0.92      0.02      0.04       560\n",
      "           M       0.36      0.68      0.47      1644\n",
      "          MP       0.36      0.25      0.29       809\n",
      "           S       0.46      0.84      0.59      2773\n",
      "          SD       0.57      0.12      0.20      1060\n",
      "           V       0.59      0.15      0.24       950\n",
      "\n",
      "    accuracy                           0.43      9288\n",
      "   macro avg       0.57      0.26      0.24      9288\n",
      "weighted avg       0.52      0.43      0.34      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = pipe.predict(X_test['words'])\n",
    "print(classification_report(y_test, pred_test, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you have expected the results that you got?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the results are unblanced,and according to the request of daily usage like text robot,etc, the accuracy should be higher than 0.43,  in this case, the results is too low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics such as accuracy should not be understood as absolute measures of performance, but should be used only to compare different classifiers. When other classifiers are not available, a simple baseline is a classifier that generates predictions by random sampling, respecting the training set&rsquo;s class distribution. This baseline is implemented by the class [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). What is the performance of the random baseline on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to evaluate the random baseline\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17743324720068906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_clf = DummyClassifier(strategy='stratified',random_state=12345)\n",
    "dum_clf.fit(X_train['words'],y_train)\n",
    "dum_clf.score(X_test['words'], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even dumber baseline is to predict, for every document, that class which appears most often in the training data. This baseline is also called the most frequent class baseline. What is the accuracy of that baseline on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.298557278208441"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Write code here to print the accuracy of the most frequent class baseline\n",
    "dum_clf = DummyClassifier(strategy='most_frequent')\n",
    "dum_clf.fit(X_train['words'],y_train)\n",
    "dum_clf.score(X_test['words'], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Creating a balanced data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw in Problem&nbsp;1, the distribution of the speeches over the eight different parties (classes) is imbalanced. One technique used to alleviate this is **undersampling**, in which one randomly removes samples from over-represented classes until all classes are represented with the same number of samples.\n",
    "\n",
    "Implement undersampling to create a balanced subset of the training data. Rerun the evaluation from Problem&nbsp;2 on the balanced data and compare the results. Summarise your results in a short text.\n",
    "\n",
    "**Hint:** Your balanced subset should consist of 5,752 speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5752, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Write code here to implement undersampling\n",
    "labels = np.unique(y_train)\n",
    "lower_size=training_data[\"party\"].value_counts()[-1]\n",
    "balanced_train = pd.DataFrame()\n",
    "for lab in labels:\n",
    "    balanced_train = balanced_train.append(training_data[training_data[\"party\"]==lab].sample(lower_size, replace=False, random_state=202111))\n",
    "    pass\n",
    "balanced_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.27      0.45      0.34       671\n",
      "          KD       0.29      0.42      0.35       821\n",
      "           L       0.27      0.44      0.33       560\n",
      "           M       0.40      0.49      0.44      1644\n",
      "          MP       0.36      0.33      0.34       809\n",
      "           S       0.78      0.29      0.42      2773\n",
      "          SD       0.45      0.39      0.42      1060\n",
      "           V       0.39      0.57      0.46       950\n",
      "\n",
      "    accuracy                           0.40      9288\n",
      "   macro avg       0.40      0.42      0.39      9288\n",
      "weighted avg       0.49      0.40      0.40      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(balanced_train[\"words\"], balanced_train[\"party\"])\n",
    "pred_p4 = pipe.predict(X_test[\"words\"])\n",
    "print(classification_report(y_test, pred_p4, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Enter the summary of your results here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result above, the accuracy decreased compared to the results in Problem 1, but the rates of precision and recall are closer, this means some useless information has been filtered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** is a specific table that is useful when analysing the performance of a classifier. In this table, both the rows and the columns correspond to classes, and each cell $(i, j)$ states how many times a sample with gold-standard class $i$ was predicted as belonging to class $j$.\n",
    "\n",
    "In scitkit-learn, the confusion matrix of a classifier is computed by the function [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). If you would rather see a visual representation, you can also use [`plot_confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html).\n",
    "\n",
    "Your task is to use the confusion matrix in order to find, for each given party $p$ in the Riksdag, that other party $p'$ which the classifier that you trained in Problem&nbsp;4 most often confuses with $p$ when it predicts the party of a speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to solve Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(pipe,X_test['words'],y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 'M',\n",
       " 'KD': 'M',\n",
       " 'L': 'C',\n",
       " 'M': 'KD',\n",
       " 'MP': 'V',\n",
       " 'S': 'M',\n",
       " 'SD': 'M',\n",
       " 'V': 'M'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_test, pred_p4), index=parties, columns=parties)\n",
    "cm1=np.array(cm)\n",
    "{cm.columns[i]:cm.columns[cm1[i,].argsort()[-2]] for i in range(8)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to reflect on whether your results make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal of the matrix is the correct label, and the off-diagonal of matrix is the incorrect label, then we could find that the M is the mostconfused with p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, you have been using the vectorizer and the Naive Bayes classifier with their default hyperparameters. When working with real-world applications, you would want to find settings for the hyperparameters that maximize the performance for the task at hand.\n",
    "\n",
    "Manually tweaking the hyperparameters of the various components of a vectorizer–classifier pipeline can be cumbersome. However, scikit-learn makes it possible to run an exhaustive search for the best hyperparameters over a grid of possible values. This method is known as **grid search**.\n",
    "\n",
    "The hyperparameters of a pipeline should never be tuned on the final test set. Instead, one should either use a separate validation set, or run cross-validation over different folds. Here we will use cross-validation.\n",
    "\n",
    "Implement a grid search with 5-fold cross-validation to find the optimal parameters in a grid defined by the following choices for the hyperparameters:\n",
    "\n",
    "* In the vectorizer, try a set-of-words (binary) model in addition to the default bag-of-words model (two possible parameter values).\n",
    "* Also in the vectorizer, try extracting bigrams in addition to unigrams (two possible parameter values).\n",
    "* In the Naive Bayes classifier, try using additive smoothing with $\\alpha \\in \\{1, 0{.}1\\}$ (two possible parameter values).\n",
    "\n",
    "Use the class [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from the scikit-learn library. Print the results of your best model, along with the parameter values that yielded these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to implement the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {  \n",
    "    \"CountVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"CountVectorizer__binary\": [True, False],\n",
    "    \"MultinomialNB__alpha\": [1,0.1]   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
       "                                       ('MultinomialNB', MultinomialNB())]),\n",
       "             param_grid={'CountVectorizer__binary': [True, False],\n",
       "                         'CountVectorizer__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'MultinomialNB__alpha': [1, 0.1]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(training_data[\"words\"], training_data[\"party\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_CountVectorizer__binary</th>\n",
       "      <th>param_CountVectorizer__ngram_range</th>\n",
       "      <th>param_MultinomialNB__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.289726</td>\n",
       "      <td>0.050395</td>\n",
       "      <td>0.517381</td>\n",
       "      <td>0.021545</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>{'CountVectorizer__binary': True, 'CountVector...</td>\n",
       "      <td>0.474686</td>\n",
       "      <td>0.468206</td>\n",
       "      <td>0.472256</td>\n",
       "      <td>0.474878</td>\n",
       "      <td>0.455024</td>\n",
       "      <td>0.469010</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.247412</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>0.516739</td>\n",
       "      <td>0.017861</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'CountVectorizer__binary': True, 'CountVector...</td>\n",
       "      <td>0.591738</td>\n",
       "      <td>0.622924</td>\n",
       "      <td>0.598623</td>\n",
       "      <td>0.564019</td>\n",
       "      <td>0.546191</td>\n",
       "      <td>0.584699</td>\n",
       "      <td>0.026889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.205578</td>\n",
       "      <td>0.083379</td>\n",
       "      <td>1.245596</td>\n",
       "      <td>0.085452</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>{'CountVectorizer__binary': True, 'CountVector...</td>\n",
       "      <td>0.397327</td>\n",
       "      <td>0.388821</td>\n",
       "      <td>0.396922</td>\n",
       "      <td>0.410454</td>\n",
       "      <td>0.390194</td>\n",
       "      <td>0.396744</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.180692</td>\n",
       "      <td>0.098577</td>\n",
       "      <td>1.226320</td>\n",
       "      <td>0.082103</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'CountVectorizer__binary': True, 'CountVector...</td>\n",
       "      <td>0.575132</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>0.587282</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>0.544976</td>\n",
       "      <td>0.567363</td>\n",
       "      <td>0.015535</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.281668</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>0.510874</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>{'CountVectorizer__binary': False, 'CountVecto...</td>\n",
       "      <td>0.515188</td>\n",
       "      <td>0.509923</td>\n",
       "      <td>0.522074</td>\n",
       "      <td>0.499595</td>\n",
       "      <td>0.485818</td>\n",
       "      <td>0.506520</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.267270</td>\n",
       "      <td>0.039287</td>\n",
       "      <td>0.522545</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'CountVectorizer__binary': False, 'CountVecto...</td>\n",
       "      <td>0.603483</td>\n",
       "      <td>0.625354</td>\n",
       "      <td>0.592143</td>\n",
       "      <td>0.563614</td>\n",
       "      <td>0.545381</td>\n",
       "      <td>0.585995</td>\n",
       "      <td>0.028437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.124744</td>\n",
       "      <td>0.039580</td>\n",
       "      <td>1.203112</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1</td>\n",
       "      <td>{'CountVectorizer__binary': False, 'CountVecto...</td>\n",
       "      <td>0.420818</td>\n",
       "      <td>0.404617</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>0.419773</td>\n",
       "      <td>0.402755</td>\n",
       "      <td>0.411407</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.120471</td>\n",
       "      <td>0.138662</td>\n",
       "      <td>1.233403</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'CountVectorizer__binary': False, 'CountVecto...</td>\n",
       "      <td>0.582827</td>\n",
       "      <td>0.602673</td>\n",
       "      <td>0.596193</td>\n",
       "      <td>0.559968</td>\n",
       "      <td>0.567261</td>\n",
       "      <td>0.581784</td>\n",
       "      <td>0.016321</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.289726      0.050395         0.517381        0.021545   \n",
       "1       2.247412      0.035919         0.516739        0.017861   \n",
       "2       7.205578      0.083379         1.245596        0.085452   \n",
       "3       7.180692      0.098577         1.226320        0.082103   \n",
       "4       2.281668      0.021527         0.510874        0.020765   \n",
       "5       2.267270      0.039287         0.522545        0.024936   \n",
       "6       7.124744      0.039580         1.203112        0.049200   \n",
       "7       7.120471      0.138662         1.233403        0.067516   \n",
       "\n",
       "  param_CountVectorizer__binary param_CountVectorizer__ngram_range  \\\n",
       "0                          True                             (1, 1)   \n",
       "1                          True                             (1, 1)   \n",
       "2                          True                             (1, 2)   \n",
       "3                          True                             (1, 2)   \n",
       "4                         False                             (1, 1)   \n",
       "5                         False                             (1, 1)   \n",
       "6                         False                             (1, 2)   \n",
       "7                         False                             (1, 2)   \n",
       "\n",
       "  param_MultinomialNB__alpha  \\\n",
       "0                          1   \n",
       "1                        0.1   \n",
       "2                          1   \n",
       "3                        0.1   \n",
       "4                          1   \n",
       "5                        0.1   \n",
       "6                          1   \n",
       "7                        0.1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'CountVectorizer__binary': True, 'CountVector...           0.474686   \n",
       "1  {'CountVectorizer__binary': True, 'CountVector...           0.591738   \n",
       "2  {'CountVectorizer__binary': True, 'CountVector...           0.397327   \n",
       "3  {'CountVectorizer__binary': True, 'CountVector...           0.575132   \n",
       "4  {'CountVectorizer__binary': False, 'CountVecto...           0.515188   \n",
       "5  {'CountVectorizer__binary': False, 'CountVecto...           0.603483   \n",
       "6  {'CountVectorizer__binary': False, 'CountVecto...           0.420818   \n",
       "7  {'CountVectorizer__binary': False, 'CountVecto...           0.582827   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.468206           0.472256           0.474878           0.455024   \n",
       "1           0.622924           0.598623           0.564019           0.546191   \n",
       "2           0.388821           0.396922           0.410454           0.390194   \n",
       "3           0.575537           0.587282           0.553890           0.544976   \n",
       "4           0.509923           0.522074           0.499595           0.485818   \n",
       "5           0.625354           0.592143           0.563614           0.545381   \n",
       "6           0.404617           0.409072           0.419773           0.402755   \n",
       "7           0.602673           0.596193           0.559968           0.567261   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.469010        0.007395                6  \n",
       "1         0.584699        0.026889                2  \n",
       "2         0.396744        0.007668                8  \n",
       "3         0.567363        0.015535                4  \n",
       "4         0.506520        0.012690                5  \n",
       "5         0.585995        0.028437                1  \n",
       "6         0.411407        0.007549                7  \n",
       "7         0.581784        0.016321                3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.39      0.27      0.32       671\n",
      "          KD       0.45      0.24      0.31       821\n",
      "           L       0.37      0.26      0.30       560\n",
      "           M       0.44      0.58      0.50      1644\n",
      "          MP       0.32      0.46      0.38       809\n",
      "           S       0.61      0.65      0.63      2773\n",
      "          SD       0.49      0.43      0.45      1060\n",
      "           V       0.50      0.42      0.46       950\n",
      "\n",
      "    accuracy                           0.48      9288\n",
      "   macro avg       0.45      0.41      0.42      9288\n",
      "weighted avg       0.48      0.48      0.48      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_p6 = grid.best_estimator_.predict(X_test[\"words\"])\n",
    "print(classification_report(y_test, pred_p6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7: Try to improve your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn makes it easy to test different vectorizer–classifier pipelines – among other things, it includes different types of logistic regression classifiers, support vector machines, and decision trees. Browse the library to see which methods are supported.\n",
    "\n",
    "Build a pipeline that you find interesting, and use grid search to find optimal settings for the hyperparameters. Print the results of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write code here to search for a better model and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import string \n",
    "import re \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(piece):\n",
    "    \n",
    "    tokens = word_tokenize(piece)\n",
    "    ## convert to lower case\n",
    "    tokens = [w.lower() for w in tokens] \n",
    "    # prepare regex for char filtering \n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word \n",
    "    stripped = [re_punc.sub('', w) for w in tokens] \n",
    "    # remove remaining tokens that are not alphabetic \n",
    "    words = [w for w in stripped if w.isalpha()] \n",
    "    # do the stemization\n",
    "    stemmer = SnowballStemmer(\"swedish\")\n",
    "    words = [stemmer.stem(w) for w in words] \n",
    "    #filter out stop words \n",
    "    stop_words = set(stopwords.words('swedish')) \n",
    "    words = [w for w in words if not w in stop_words] \n",
    "    \n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "# define stemmer will be used in preprocessing\n",
    "stemmer = SnowballStemmer(\"swedish\")\n",
    "# define punctuation table\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "# define stopwords\n",
    "stopwords_sw = set(stopwords.words(\"swedish\"))\n",
    "\n",
    "def preprocess1(text):\n",
    "    words = []\n",
    "    for t in word_tokenize(text):\n",
    "        t_ = t.lower().translate(table)\n",
    "        if(not t_ in stopwords_sw and t_.isalpha()):\n",
    "            words.append(stemmer.stem(t_))\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_kpi(pipe):\n",
    "    pipe.fit(X_train[\"words\"], y_train)\n",
    "    test_pred = pipe.predict(X_test[\"words\"])\n",
    "    print(classification_report(y_test, test_pred, target_names=parties))\n",
    "    acc = pipe.score(X_test[\"words\"],y_test)\n",
    "    print('The average accuracy of this model is',acc)\n",
    "    return acc\n",
    "countVectorizer = CountVectorizer(tokenizer=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.56      0.11      0.18       671\n",
      "          KD       0.60      0.05      0.10       821\n",
      "           L       0.44      0.05      0.09       560\n",
      "           M       0.38      0.66      0.48      1644\n",
      "          MP       0.34      0.39      0.36       809\n",
      "           S       0.49      0.77      0.60      2773\n",
      "          SD       0.52      0.24      0.33      1060\n",
      "           V       0.54      0.24      0.33       950\n",
      "\n",
      "    accuracy                           0.45      9288\n",
      "   macro avg       0.48      0.31      0.31      9288\n",
      "weighted avg       0.48      0.45      0.39      9288\n",
      "\n",
      "The average accuracy of this model is 0.4469207579672696\n"
     ]
    }
   ],
   "source": [
    "pipeNB = Pipeline([(\"CountVectorizer\", countVectorizer), (\"MultinomialNB\", MultinomialNB())])\n",
    "res_MultinomialNB = model_kpi(pipeNB)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.39      0.35      0.37       671\n",
      "          KD       0.49      0.24      0.32       821\n",
      "           L       0.41      0.35      0.38       560\n",
      "           M       0.49      0.52      0.50      1644\n",
      "          MP       0.31      0.42      0.36       809\n",
      "           S       0.56      0.73      0.63      2773\n",
      "          SD       0.49      0.38      0.43      1060\n",
      "           V       0.57      0.30      0.39       950\n",
      "\n",
      "    accuracy                           0.49      9288\n",
      "   macro avg       0.46      0.41      0.42      9288\n",
      "weighted avg       0.49      0.49      0.48      9288\n",
      "\n",
      "The average accuracy of this model is 0.488479758828596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeLR=Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"LogisticRegression_classifier\", LogisticRegression(random_state=202111, \n",
    "                                                 multi_class=\"multinomial\", \n",
    "                                                 solver=\"lbfgs\", \n",
    "                                                 max_iter=5000))])\n",
    "res_LogisticRegression=model_kpi(pipeLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:59:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.51      0.41      0.45       671\n",
      "          KD       0.65      0.28      0.39       821\n",
      "           L       0.54      0.41      0.47       560\n",
      "           M       0.50      0.50      0.50      1644\n",
      "          MP       0.37      0.31      0.34       809\n",
      "           S       0.49      0.83      0.62      2773\n",
      "          SD       0.59      0.30      0.40      1060\n",
      "           V       0.63      0.30      0.41       950\n",
      "\n",
      "    accuracy                           0.51      9288\n",
      "   macro avg       0.54      0.42      0.45      9288\n",
      "weighted avg       0.53      0.51      0.49      9288\n",
      "\n",
      "The average accuracy of this model is 0.5075366063738157\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "pipeXGB=Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"XGBClassifier\", XGBClassifier(objective=\"multi:softprob\",random_state=202111))])\n",
    "\n",
    "res_xgboost = model_kpi(pipeXGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.36      0.35      0.36       671\n",
      "          KD       0.38      0.22      0.28       821\n",
      "           L       0.31      0.33      0.32       560\n",
      "           M       0.46      0.47      0.46      1644\n",
      "          MP       0.28      0.39      0.32       809\n",
      "           S       0.56      0.66      0.60      2773\n",
      "          SD       0.42      0.35      0.39      1060\n",
      "           V       0.48      0.29      0.36       950\n",
      "\n",
      "    accuracy                           0.45      9288\n",
      "   macro avg       0.41      0.38      0.39      9288\n",
      "weighted avg       0.45      0.45      0.44      9288\n",
      "\n",
      "The average accuracy of this model is 0.448535745047373\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeLSVM=Pipeline([(\"countVectorizer\", countVectorizer), \n",
    "               (\"classifier\", LinearSVC(max_iter=10000))])\n",
    "\n",
    "res_LinearSVM = model_kpi(pipeLSVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4469207579672696\n",
      "0.488479758828596\n",
      "0.5075366063738157\n",
      "0.448535745047373\n"
     ]
    }
   ],
   "source": [
    "print(res_MultinomialNB)\n",
    "print(res_LogisticRegression)\n",
    "print(res_xgboost)\n",
    "print(res_LinearSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data above, we could find that the xgboost has the highest accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:03:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:04:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:05:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:07:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:11:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:12:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:13:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:15:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:17:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:18:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:20:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:21:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:24:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:26:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:27:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:30:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:34:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:35:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:36:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:37:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:38:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:43:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:44:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:46:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:48:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:00:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:07:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:10:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:11:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:12:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:13:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:16:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:19:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:21:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:22:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:23:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:25:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:28:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:33:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:34:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:36:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:40:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:43:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:47:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:53:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:58:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:00:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:02:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:18:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:21:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:24:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:25:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:26:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:27:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:33:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:40:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:44:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:47:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:50:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:01:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:02:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:04:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:10:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'XGBClassifier__colsample_bytree': 0.2, 'XGBClassifier__max_depth': 4, 'countVectorizer__binary': False, 'countVectorizer__ngram_range': (1, 1)}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.52      0.41      0.46       671\n",
      "          KD       0.65      0.30      0.41       821\n",
      "           L       0.53      0.44      0.48       560\n",
      "           M       0.53      0.47      0.50      1644\n",
      "          MP       0.40      0.28      0.33       809\n",
      "           S       0.48      0.85      0.61      2773\n",
      "          SD       0.62      0.32      0.43      1060\n",
      "           V       0.65      0.29      0.40       950\n",
      "\n",
      "    accuracy                           0.51      9288\n",
      "   macro avg       0.55      0.42      0.45      9288\n",
      "weighted avg       0.54      0.51      0.49      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"countVectorizer__ngram_range\": [(1,1), (1,2)],\n",
    "    \"countVectorizer__binary\": [True, False],\n",
    "    \"XGBClassifier__colsample_bytree\": [0.2,0.6,0.9],\n",
    "    \"XGBClassifier__max_depth\": [2,3,4]\n",
    "    \n",
    "}\n",
    "grid = GridSearchCV(pipeXGB, param_grid=parameters, cv=3, verbose=1)\n",
    "\n",
    "grid.fit(training_data[\"words\"], training_data[\"party\"])\n",
    "pred_p7 = grid.best_estimator_.predict(X_test[\"words\"])\n",
    "print(grid.best_params_)\n",
    "print(classification_report(y_test, pred_p7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reflection questions are questions that you could be asked in the oral exam. Try to answer each of them in the form of a short text and enter it in the cell below. You will get feedback on your answers from your lab assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 2.1:** Summarise the results of your experiments for Problem&nbsp;2. Are your results ‘good’ or ‘bad’? How do you determine that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think that results is not so good. This conclusion depends on the accurray, precision and recall of different parties. First, the accurracy of training dataset and test dataset is quite different, that the accurracy of test data is about half of training data. Besides, the precision and the recall of differernt parties is quite different, which some take high rates while some take low rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 2.2:** Summarise the results of your experiments for Problem&nbsp;4. Would you think that your results are typical even for other classification tasks? How would *oversampling* have looked like for this task? When would you use undersampling, when oversampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think this result is not typical because of the low accuracy. As for the oversampling, the rates different of precision and recall would be much larger, and the accuracy might increase. For the question about when to use undersampling or oversampling, we think that it depends on the quality of the data. For example, if the data is unbalanced, as the data in this lab, we need to use the undersampling to filter the useless information. When the data is balanced, we could use oversampling to strengthen the feature of the data when training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 2.3:** Which model performed best in your experiments for Problem&nbsp;6? Why is it important to do a hyperparameter search before drawing conclusions about the performance of a model? Why is it often not done, anyway? Why should you never tune hyperparameters on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the xgboost model performed best in the experiments. Hyperparameter search is important because when we training the model, our parameter might not be the best parammeter, which means the performance of the model maybe not the best, in this case, we cannot ensure the model we choose is the best model, so we need to do a hyperparameter search before drawing conclusions. We don't often it because it usually takes lots of time to do the search and sometimes, the low perforamce of model may be caused by the quality of data set. We should never tune hyperparameters on the test set because the test set is used for evalute the performance of the model, when we tune hyperparameters, we are actullay doing the training of the model, which needs to do in the training set or the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Enter your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing L2! 👍**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
